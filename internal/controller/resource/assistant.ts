import type { Request, Response} from "express";
import { ITalkAssistant } from "../../ai/type";

export const resourceAssistant = () => async (req: Request, res: Response) => {
  res.status(200);
  res.json(data);
  res.end();
};

const data: ITalkAssistant[] = [
  {
    typeCommunication: "local",
    assistantId: "1",
    title: "anthropic",
    description: "claude-3-opus-20240229",
    emoji: "question-mark-circle-16",
    avatar: "",
    model: "anthropic" + "__" + "claude-3-opus-20240229",
    modelTemperature: "0.7",
    promptSystem: "Tell true",
    webhookUrl: undefined,
    additionalData: undefined,
    snippet: undefined,
    isLocal: true,
  },
  {
    typeCommunication: "local",
    assistantId: "2",
    title: "cohere",
    description: "command",
    emoji: "question-mark-circle-16",
    avatar: "",
    model: "cohere" + "__" + "command",
    modelTemperature: "0.7",
    promptSystem: "Tell true",
    webhookUrl: undefined,
    additionalData: undefined,
    snippet: undefined,
    isLocal: true,
  },
  {
    typeCommunication: "local",
    assistantId: "3",
    title: "groq",
    description: "llama3-8b-8192",
    emoji: "question-mark-circle-16",
    avatar: "",
    model: "groq" + "__" + "llama3-8b-8192",
    modelTemperature: "0.7",
    promptSystem: "Tell true",
    webhookUrl: undefined,
    additionalData: undefined,
    snippet: undefined,
    isLocal: true,
  },
  {
    typeCommunication: "local",
    assistantId: "4",
    title: "ollama",
    description: "llama3",
    emoji: "question-mark-circle-16",
    avatar: "",
    model: "ollama" + "__" + "llama3",
    modelTemperature: "0.7",
    promptSystem: "Tell true",
    webhookUrl: undefined,
    additionalData: undefined,
    snippet: undefined,
    isLocal: true,
  },
  {
    typeCommunication: "local",
    assistantId: "5",
    title: "openai",
    description: "gpt-4o",
    emoji: "question-mark-circle-16",
    avatar: "",
    model: "openai" + "__" + "gpt-4o",
    modelTemperature: "0.7",
    promptSystem: "Tell true",
    webhookUrl: undefined,
    additionalData: undefined,
    snippet: undefined,
    isLocal: true,
  },
  {
    typeCommunication: "local",
    assistantId: "6",
    title: "perplexity",
    description: "llama-3-sonar-small-32k-online",
    emoji: "question-mark-circle-16",
    avatar: "",
    model: "perplexity" + "__" + "llama-3-sonar-small-32k-online",
    modelTemperature: "0.7",
    promptSystem: "Tell true",
    webhookUrl: undefined,
    additionalData: undefined,
    snippet: undefined,
    isLocal: true,
  },
  {
    typeCommunication: "local",
    assistantId: "0bb69d53-0389-49a4-a593-b75124fe25a7",
    title: "Default",
    description: "Chatty, easygoing digital sidekick",
    emoji: "question-mark-circle-16",
    avatar: "",
    model: "openai__gpt-4o",
    modelTemperature: "0.7",
    promptSystem:
      "You are an AI assistant designed for ultra-concise, engaging conversations. Follow these rules: \n\r\n\r - Use the fewest words possible while maintaining clarity, impact and natural language \n\r - Keep a friendly, casual tone with occasional colloquialisms \n\r - Always wrap code with triple backticks and keywords with single backticks \n\r - Ask for clarification to avoid assumptions \n\r - Detect intentions and emotional states to tailor responses perfectly. \n\r - Focus solely on instructions and provide relevant, comprehensive responses \n\r - Never repeat info or mention limitations \n\r - Simplify complex tasks; provide the best output possible \n\r - Prioritize user needs; tailor responses to their context and goals \n\r - When asked for specific content, start response with requested info immediately \n\r - Continuously improve based on user feedback \n\r\n\r Let's keep it ultra-concise and engaging!",
    webhookUrl: undefined,
    additionalData: undefined,
    snippet: undefined,
    isLocal: true,
  },
]